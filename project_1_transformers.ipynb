{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eSNCOQgs9xZ"
      },
      "source": [
        "<h1><center>\n",
        "    Implementing, fine-tuning and visualizing transformer architectures. <br/>\n",
        "  \n",
        "    \n",
        "    Project 1\n",
        "</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgsVYaLIs9xc"
      },
      "source": [
        "# Task 1\n",
        "Implement the feed-forward pass of the original transformer network using only numpy, i.e. without machine learning frameworks.\n",
        "\n",
        "Note: All subtasks are voluntary and rather a guide-line of how we would implement the forward pass. You can also choose a different order for implementing the different parts or implement everything in one class/function. The forward pass should return an numpy array.\n",
        "\n",
        "Please initialize the weights using Glorot initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ze8oZK4Ss9xe"
      },
      "outputs": [],
      "source": [
        "# You will test your implementation on a single array:\n",
        "import numpy as np\n",
        "forward_pass_array = np.array([101, 400, 500, 600, 107, 102])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHgV0NL0s9xg"
      },
      "source": [
        "## Task 1.1\n",
        "Implement the sinus/cosinus positional encoding used in the original paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762). Implement the token embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# token embedding matrix 1000x512 random floats golorot normal\n",
        "word_embedding = np.random.\n",
        "# select words from the embedding matrix by index\n",
        "\n",
        "# matrix 6 x 512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9XQOngbhs9xh"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(positions:list, embeddings:list, d_model:int = 512):\n",
        "    \"\"\"\n",
        "    returns a matrix\n",
        "    pos is the position, embeddings is a vector and d_model is the model dimension\n",
        "    we use sine and cosine functions of different frequencies\n",
        "\n",
        "    :param pos: position aka t \n",
        "    :type pos: list\n",
        "    :param embeddings: size of the embedding\n",
        "    :type i: list\n",
        "    :param d_model: model dimensions\n",
        "    :type d_model: int\n",
        "    \"\"\"\n",
        "    result_matrix = np.zeros((len(positions), len(embeddings)))\n",
        "    for pos in range(len(positions)):\n",
        "        for i in range(len(embeddings)):\n",
        "            if i % 2 == 0:\n",
        "                result_matrix[pos,i] = np.sin(pos / (10000 ** (i / d_model)))\n",
        "            else:\n",
        "                result_matrix[pos,i] = np.cos(pos / (10000 ** ((i - 1) / d_model)))\n",
        "    return result_matrix\n",
        "\n",
        "# Now we can create the positional encoding matrix\n",
        "\n",
        "\n",
        "positional_encoding_matrix = positional_encoding(forward_pass_array, forward_pass_array[0], len(forward_pass_array[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 1.        , 0.        , 1.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.84147098, 0.54030231, 0.04639922, 0.99892298, 0.00215443,\n",
              "        0.99999768]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positional_encoding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 6)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positional_encoding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axt_BqrJs9xh"
      },
      "source": [
        "## Task 1.2\n",
        "Implement a dense layer with the number of hidden units as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dense_layer(X:np.array, hidden_units:int):\n",
        "    \"\"\"\n",
        "    Input and output matrices are of same dimension\n",
        "    Single dense layer with a specified number of hidden units\n",
        "\n",
        "\n",
        "    :param X: input matrix\n",
        "    :type X: np.array\n",
        "    :param hidden_units: number of hidden units\n",
        "    :type hidden_units: int\n",
        "    \"\"\"\n",
        "    input_dim = X.shape[1]\n",
        "    \n",
        "    # golorot normal initialization of the weights\n",
        "    weight = np.random.normal(loc=0.0, scale=np.sqrt(2.0 / (input_dim + hidden_units)), size=(input_dim, hidden_units, ))\n",
        "\n",
        "    bias = np.zeros(hidden_units)\n",
        "    \n",
        "    # we use the dot product to calculate the output of the layer\n",
        "    return np.matmul(X, weight) + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 512)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense_output = dense_layer(positional_encoding_matrix, 512)\n",
        "dense_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsSfCiNKs9xj"
      },
      "source": [
        "## Task 1.3\n",
        "Implement all activation function such that they are compatible with the dense layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tg6qEQPws9xk"
      },
      "outputs": [],
      "source": [
        "# Implement all activation function such that they are compatible with the dense layer.\n",
        "def activation(hidden_layer:np.array):\n",
        "    \"\"\" Relu activation\n",
        "\n",
        "    :param hidden_layer: hidden layer for activation\n",
        "    :type hidden_layer: np.array\n",
        "    :param activation: ReLU activated hidden layer\n",
        "    :type activation: np.array\n",
        "    \"\"\"\n",
        "    # Implement the relu activation function\n",
        "    return np.maximum(0, hidden_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0158035 , 0.1954243 , 0.11861342, ..., 0.0784443 , 0.04377799,\n",
              "        0.        ],\n",
              "       [0.        , 0.25335698, 0.05216577, ..., 0.03803676, 0.02747156,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "activation(dense_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lyam5O3s9xl"
      },
      "source": [
        "## Task 1.4\n",
        "Implement the skip (residual) connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JeaLA_N5s9xn"
      },
      "outputs": [],
      "source": [
        "#Implement the skip (residual) connections.\n",
        "def skip_connections(hidden_layer, input_layer):\n",
        "    \"\"\"Skip connection \n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    :param input_layer: _description_\n",
        "    :type input_layer: _type_\n",
        "    \"\"\"\n",
        "    return hidden_layer + input_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8cryIa1s9xn"
      },
      "source": [
        "## Task 1.5\n",
        "Implement layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gyYe-KH3s9xo"
      },
      "outputs": [],
      "source": [
        "# Implement layer normalization.\n",
        "def normalisation_layer(hidden_layer, mean, variance):\n",
        "    \"\"\" check the dimensionality should be normalised over all values \n",
        "    instead of columns wise normalisation used in batch normalisation\n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    :param mean: _description_\n",
        "    :type mean: _type_\n",
        "    :param variance: _description_\n",
        "    :type variance: _type_\n",
        "    \"\"\"\n",
        "    # Implement the layer normalization\n",
        "    mean = np.mean(hidden_layer, axis=1, keepdims=True)\n",
        "    variance = np.var(hidden_layer, axis=1, keepdims=True)\n",
        "    return (hidden_layer - mean) / np.sqrt(variance + 1e-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKIJqC2us9xp"
      },
      "source": [
        "## Task 1.6\n",
        "Implement dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RUhGgH_qs9xq"
      },
      "outputs": [],
      "source": [
        "# Implement dropout\n",
        "def dropout(hidden_layer, dropout_rate):\n",
        "    \"\"\"dropout \n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    :param dropout_rate: _description_\n",
        "    :type dropout_rate: _type_\n",
        "    \"\"\"\n",
        "    # Implement the dropout\n",
        "    return hidden_layer * np.random.binomial(1, 1 - dropout_rate, size=hidden_layer.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtCKnQJys9xy"
      },
      "source": [
        "## Task 1.7\n",
        "Implement the attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def softmax(input_matrix, axis=1):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    \"\"\"\n",
        "    # Implement the softmax function\n",
        "    return np.exp(input_matrix) / np.sum(np.exp(input_matrix), axis=axis, keepdims=True)\n",
        "\n",
        "# implement a multi-head attention layer\n",
        "def multihead_attention(query, key, value, num_heads, mask=None):\n",
        "    \"\"\"\n",
        "    Applies multi-head attention to the given query, key, and value tensors.\n",
        "\n",
        "    :param query: A NumPy array representing the query tensor. This tensor should have shape `(batch_size, sequence_length, feature_dim)`.\n",
        "    :type query: numpy.ndarray\n",
        "    :param key: A NumPy array representing the key tensor. This tensor should have shape `(batch_size, sequence_length, feature_dim)`.\n",
        "    :type key: numpy.ndarray\n",
        "    :param value: A NumPy array representing the value tensor. This tensor should have shape `(batch_size, sequence_length, feature_dim)`.\n",
        "    :type value: numpy.ndarray\n",
        "    :param num_heads: An integer representing the number of attention heads to use.\n",
        "    :type num_heads: int\n",
        "    :param mask: An optional mask tensor. This tensor should have shape `(batch_size, sequence_length)` and should contain `0`s\n",
        "        where elements should be masked and `1`s elsewhere.\n",
        "    :type mask: numpy.ndarray, optional\n",
        "    :return: A tuple containing the output tensor of the multi-head attention and the attention weights.\n",
        "        The output tensor has shape `(batch_size, sequence_length, feature_dim)`.\n",
        "        The attention weights tensor has shape `(batch_size, num_heads, sequence_length, sequence_length)`.\n",
        "    :rtype: tuple[numpy.ndarray, numpy.ndarray]\n",
        "\n",
        "    **Example**\n",
        "\n",
        "query = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "key = np.array([[7, 8, 9], [10, 11, 12]])\n",
        "value = np.array([[13, 14, 15], [16, 17, 18]])\n",
        "num_heads = 2\n",
        "output, attention_weights = multihead_attention(query, key, value, num_heads)\n",
        "print(output)\n",
        "    [[ 6.902019   7.1488886  7.395758 ]\n",
        "     [15.902019  16.14889   16.39576  ]]\n",
        "print(attention_weights)\n",
        "    [[[0.33333334 0.6666667 ]\n",
        "      [0.33333334 0.6666667 ]]\n",
        "     [[0.33333334 0.6666667 ]\n",
        "      [0.33333334 0.6666667 ]]]\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the number of features for the query, key, and value tensors\n",
        "    feature_dim = query.shape[-1]\n",
        "\n",
        "    # Split the query, key, and value tensors into num_heads separate tensors\n",
        "    query = np.reshape(query, (-1, num_heads, feature_dim // num_heads))\n",
        "    key = np.reshape(key, (-1, num_heads, feature_dim // num_heads))\n",
        "    value = np.reshape(value, (-1, num_heads, feature_dim // num_heads))\n",
        "\n",
        "    # Transpose the query, key, and value tensors to prepare for matrix multiplication\n",
        "    query = np.transpose(query, (1, 0, 2))\n",
        "    key = np.transpose(key, (1, 0, 2))\n",
        "    value = np.transpose(value, (1, 0, 2))\n",
        "\n",
        "    # Compute the dot products of the query and key tensors\n",
        "    dot_products = np.matmul(query, key.transpose(0, 2, 1))\n",
        "\n",
        "    # Scale the dot products by the square root of the feature dimension\n",
        "    dot_products = np.sqrt(feature_dim // num_heads)\n",
        "\n",
        "    # Apply the mask (if any)\n",
        "    if mask is not None:\n",
        "        dot_products = np.where(mask == 0, -1e9, dot_products)\n",
        "\n",
        "    # Apply the softmax function along the last dimension\n",
        "    attention_weights = softmax(dot_products, axis=-1)\n",
        "\n",
        "    # Compute the weighted sum of the value tensors using the attention weights\n",
        "    output = np.matmul(attention_weights, value)\n",
        "\n",
        "    # Transpose and reshape the output tensor to match the shape of the input tensors\n",
        "    output = np.transpose(output, (1, 0, 2))\n",
        "    output = np.reshape(output, (-1, feature_dim))\n",
        "\n",
        "    return output, attention_weights\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[38], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m13\u001b[39m, \u001b[39m14\u001b[39m, \u001b[39m15\u001b[39m], [\u001b[39m16\u001b[39m, \u001b[39m17\u001b[39m, \u001b[39m18\u001b[39m]])\n\u001b[1;32m      4\u001b[0m num_heads \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m----> 5\u001b[0m output, attention_weights \u001b[39m=\u001b[39m multihead_attention(query, key, value, num_heads)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(output)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(attention_weights)\n",
            "Cell \u001b[0;32mIn[37], line 75\u001b[0m, in \u001b[0;36mmultihead_attention\u001b[0;34m(query, key, value, num_heads, mask)\u001b[0m\n\u001b[1;32m     72\u001b[0m attention_weights \u001b[39m=\u001b[39m softmax(dot_products, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[39m# Compute the weighted sum of the value tensors using the attention weights\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmatmul(attention_weights, value)\n\u001b[1;32m     77\u001b[0m \u001b[39m# Transpose and reshape the output tensor to match the shape of the input tensors\u001b[39;00m\n\u001b[1;32m     78\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(output, (\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m))\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
          ]
        }
      ],
      "source": [
        "\n",
        "query = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "key = np.array([[7, 8, 9], [10, 11, 12]])\n",
        "value = np.array([[13, 14, 15], [16, 17, 18]])\n",
        "num_heads = 2\n",
        "output, attention_weights = multihead_attention(query, key, value, num_heads)\n",
        "print(output)\n",
        "print(attention_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nweispoRs9xz"
      },
      "outputs": [],
      "source": [
        "# Implement the attention mechanism.\n",
        "# softmax function from numpy.\n",
        "\n",
        "\n",
        "\n",
        "def softmax(input_matrix):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    \"\"\"\n",
        "    # Implement the softmax function\n",
        "    return np.exp(input_matrix) / np.sum(np.exp(input_matrix), axis=1, keepdims=True)\n",
        " \n",
        "def attention(Q, K, V, dimension_k, mask=None, dropout=None):\n",
        "    \"\"\"Compute 'Scaled Dot Product Attention'\n",
        "\n",
        "    :param Q: _description_\n",
        "    :type Q: _type_\n",
        "    :param K: _description_\n",
        "    :type K: _type_\n",
        "    :param V: _description_\n",
        "    :type V: _type_\n",
        "    \"\"\"\n",
        "    # Implement the attention mechanism\n",
        "    return np.matmul(softmax(np.matmul(Q, K.T) / np.sqrt(dimension_k)), V)\n",
        "\n",
        "def decoder_mask(input_matrix:np.ndarray):\n",
        "    \"\"\"mask the attention to the decoder so that the model does not cheat by looking ahead in the sequence.\n",
        "\n",
        "    :param input_matrix: the output of the attion mechanism\n",
        "    :type input_matrix: np.ndarray\n",
        "    \"\"\"    \n",
        "    attn_shape = input_matrix.shape\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return input_matrix[subsequent_mask == -np.inf].reshape(attn_shape)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yApJ-i6Ws9x0"
      },
      "source": [
        "## Task 1.8\n",
        "Implement the positonal feed-forward network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgOD1435s9x1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhyAVEIas9x1"
      },
      "source": [
        "## Task 1.9\n",
        "Implement the encoder attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhVWrtbls9x1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4lA-qajs9x2"
      },
      "source": [
        "## Task 1.10\n",
        "Implement the encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnDRK_aPs9x2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzqspeJ4s9x2"
      },
      "source": [
        "## Task 1.11\n",
        "Implement the decoder attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEgfyNvNs9x3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lOPMNIps9x3"
      },
      "source": [
        "## Task 1.12\n",
        "Implement the encoder-decoder attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLQ8aRPTs9x3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZW9JEaUs9x4"
      },
      "source": [
        "## Task 1.13\n",
        "Implement the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bQZWQrns9x4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtPOUkLRs9x4"
      },
      "source": [
        "## Task 1.14\n",
        "Implement the transformer architecture (e.g. by creating a Transformer class that includes the steps before)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VEtaTIR_s9x5"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "incomplete input (1776112302.py, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "class Transformer():\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARMrtlX-s9x5"
      },
      "source": [
        "## Task 1.15\n",
        "Test the forward pass using the follow array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVwUBmyqs9x6"
      },
      "outputs": [],
      "source": [
        "forward_pass_array = np.array([101, 400, 500, 600, 107, 102])\n",
        "Transformer(forward_pass_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVQhmTVs9x6"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a8mqbvis9x7"
      },
      "source": [
        "In the following, we want to use pretrained models. From here on, you are allowed to use any machine learning frame work of your choice. Moreover, you will use [Hugging Face](https://huggingface.co/) which is compatible with tensorflow, keras, torch and other machine learning frameworks.\n",
        "\n",
        "We want to fine-tune a pretrained model to determine whether Yelp reviews are positive or negative. The data set is available for [Tensorflow](https://www.tensorflow.org/datasets/catalog/yelp_polarity_reviews) and [(py)torch](https://pytorch.org/text/stable/datasets.html#yelpreviewpolarity). Given the text of a review, we want to determine whether the yelp review is positive and negative. The data set is pre-split into training and test set. Please use the training data to fine-tune your model, while using the test data to evaluate your models performance. This exercise does not necessarily end in having a SOTA model, the goal is for you to use and fine-tune SOTA pretrained large language models.\n",
        "\n",
        "Problem Setting:\n",
        "\n",
        "The label $y$ to a Yelp review $T$ is either positive or negative. Given a Yelp Review $T$ and a polarity feedback $y$ determine whether the Review $T$ is positive or negative. The training set $\\mathcal{D} = \\{(T_1, y_1), \\ldots, (T_N, y_N)\\}$, where $T_i$ is review $i$ and $y_i$ is $T_i$'s polarity feedback. A suitable evaluation metric for this type of problem is $\\rightarrow$ see Theory Question 1.\n",
        "\n",
        "In the following, please solve all subtasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeeKpVG6s9x7"
      },
      "source": [
        "## Theory Question 1\n",
        "Which metric is threshold independent to evaluate the problem setting described in Task 2. Please list pros and cons of three different metrics that might be suitable, define an evaluation protocol and decide which evaluation suits this problem best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXMOXCwCs9x8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDmbdj-Ds9x8"
      },
      "source": [
        "## Task 2.0\n",
        "Load the Yelp Review Polarity dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-cPKGuus9x9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlRochOKs9x9"
      },
      "source": [
        "## Task 2.1\n",
        "Decide on a suitable language model from the HuggingFace model zoo (a library providing pretrained models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nap1PL1es9x9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h0rgHM9s9x-"
      },
      "source": [
        "## Task 2.2\n",
        "\n",
        "For the model to process the intended way, we need the tokenizer that was used during training. Luckily Hugging Face  provides both pretrained models and tokenizer. After in Task 2.1 decided for a language model, please load the corresponding tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klRNm499s9x-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZwxqrDs9x_"
      },
      "source": [
        "## Task 2.3\n",
        "Load the language model from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dfk7kebFs9x_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRcPP6sPs9x_"
      },
      "source": [
        "## Task 2.4\n",
        "Fine-tune your model on the Yelp Review Polarity training data set. Note: If you have computational limitations consider fine-tuning only on part of the training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13Nx72o_s9yA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaGqCcEs9yB"
      },
      "source": [
        "## Task 2.5\n",
        "Evaluate your model, following the evaluation protocol you defined in Theory Question 1, on the test part of the Yelp Review Polarity data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdqnnJaGs9yC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEibR93Hs9yC"
      },
      "source": [
        "# Task 3\n",
        "Visualize and interpret the attention weights of one correctly and one of the incorrectly classified examples of the Yelp Review Polarity test data using [BertViz](https://github.com/jessevig/bertviz)'s model_view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1YPLr3cs9yC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm05PFcMs9yD"
      },
      "source": [
        "## Theory Question 2\n",
        "In your own words, describe how the attention mechanism in a transformer works in the case of self-attention and cross-attention, identifying in each case the keys, queries, and values. Give two examples of alignment models and describe how they affect the output using a simple example. This part of the written report can be done in collaboration with your group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDj5j60Rs9yD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u-8cqs0s9yD"
      },
      "source": [
        "# Task 4\n",
        "Please describe your team's implementation of this project, including your personal contribution, in 1000-1500 characters. Each team member must explain the main aspects of the team's implementation, and may not discuss this summary with other students. You are allowed to use figures and tables to clarify. This summary constitutes a separately and individually graded piece of work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7FJBhNPs9yE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "f94a2e1669021a1b826617800504e937bcc4e1c8d0dde6e9bfebb8455f6fae62"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
