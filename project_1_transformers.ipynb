{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eSNCOQgs9xZ"
      },
      "source": [
        "<h1><center>\n",
        "    Implementing, fine-tuning and visualizing transformer architectures. <br/>\n",
        "  \n",
        "    \n",
        "    Project 1\n",
        "</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgsVYaLIs9xc"
      },
      "source": [
        "# Task 1\n",
        "Implement the feed-forward pass of the original transformer network using only numpy, i.e. without machine learning frameworks.\n",
        "\n",
        "Note: All subtasks are voluntary and rather a guide-line of how we would implement the forward pass. You can also choose a different order for implementing the different parts or implement everything in one class/function. The forward pass should return an numpy array.\n",
        "\n",
        "Please initialize the projectionss using Glorot initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {
        "id": "Ze8oZK4Ss9xe"
      },
      "outputs": [],
      "source": [
        "# You will test your implementation on a single array:\n",
        "import numpy as np\n",
        "forward_pass_array = np.array([101, 400, 500, 600, 107, 102])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_weights(y_rows, x_cols):\n",
        "    \"\"\"\n",
        "    Initialise the weights of a layer with Glorot normal initialisation.\n",
        "    \n",
        "    :param input_size: The number of inputs to the layer.\n",
        "    :type input_size: int\n",
        "    :param output_size: The number of outputs of the layer.\n",
        "    :type output_size: int\n",
        "    :return: The initialised weights.\n",
        "    :rtype: np.ndarray\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc=0.0, scale=np.sqrt(2.0 / (y_rows + x_cols)), size=(y_rows, x_cols, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 512)"
            ]
          },
          "execution_count": 359,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# token embedding matrix 1000x512 random floats golorot normal\n",
        "word_embeddings = init_weights(1000, 512)\n",
        "word_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.01489839, -0.04439217, -0.00110594, ...,  0.00632248,\n",
              "         0.01246789, -0.02591219],\n",
              "       [ 0.00893764,  0.06149519,  0.03203489, ..., -0.0581485 ,\n",
              "         0.0009087 ,  0.03679372],\n",
              "       [-0.01831154, -0.02662101,  0.04415341, ..., -0.00783613,\n",
              "        -0.05300926, -0.04639265],\n",
              "       ...,\n",
              "       [-0.06366031,  0.03155351, -0.01930988, ..., -0.00356679,\n",
              "         0.03610266, -0.01961871],\n",
              "       [ 0.01572552,  0.04296135,  0.03443194, ...,  0.01231307,\n",
              "        -0.02197808, -0.00327224],\n",
              "       [-0.03225609,  0.01967155,  0.02092852, ..., -0.01605005,\n",
              "         0.04499853,  0.01511265]])"
            ]
          },
          "execution_count": 360,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_embeddings = word_embeddings[forward_pass_array]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHgV0NL0s9xg"
      },
      "source": [
        "## Task 1.1\n",
        "Implement the sinus/cosinus positional encoding used in the original paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762). Implement the token embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {
        "id": "9XQOngbhs9xh"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(positions:list,  d_model:int = 512):\n",
        "    \"\"\"\n",
        "    returns a matrix\n",
        "    pos is the position, embeddings is a vector and d_model is the model dimension\n",
        "    we use sine and cosine functions of different frequencies\n",
        "\n",
        "    :param pos: position aka t \n",
        "    :type pos: list\n",
        "    :param embeddings: size of the embedding\n",
        "    :type i: list\n",
        "    :param d_model: model dimensions\n",
        "    :type d_model: int\n",
        "    \"\"\"\n",
        "    result_matrix = np.zeros((len(positions), d_model))\n",
        "    for pos in range(len(positions)):\n",
        "        for i in range(d_model):\n",
        "            if i % 2 == 0:\n",
        "                result_matrix[pos,i] = np.sin(pos / (10000 ** (i / d_model)))\n",
        "            else:\n",
        "                result_matrix[pos,i] = np.cos(pos / (10000 ** ((i - 1) / d_model)))\n",
        "    return result_matrix\n",
        "\n",
        "# Now we can create the positional encoding matrix\n",
        "\n",
        "\n",
        "positional_encoding_matrix = positional_encoding(selected_embeddings, len(selected_embeddings[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 8.41470985e-01,  5.40302306e-01,  8.21856190e-01, ...,\n",
              "         9.99999994e-01,  1.03663293e-04,  9.99999995e-01],\n",
              "       [ 9.09297427e-01, -4.16146837e-01,  9.36414739e-01, ...,\n",
              "         9.99999977e-01,  2.07326584e-04,  9.99999979e-01],\n",
              "       [ 1.41120008e-01, -9.89992497e-01,  2.45085415e-01, ...,\n",
              "         9.99999948e-01,  3.10989874e-04,  9.99999952e-01],\n",
              "       [-7.56802495e-01, -6.53643621e-01, -6.57166863e-01, ...,\n",
              "         9.99999908e-01,  4.14653159e-04,  9.99999914e-01],\n",
              "       [-9.58924275e-01,  2.83662185e-01, -9.93854779e-01, ...,\n",
              "         9.99999856e-01,  5.18316441e-04,  9.99999866e-01]])"
            ]
          },
          "execution_count": 363,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positional_encoding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 512)"
            ]
          },
          "execution_count": 364,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positional_encoding_matrix.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Axt_BqrJs9xh"
      },
      "source": [
        "## Task 1.2\n",
        "Implement a dense layer with the number of hidden units as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dense_layer(X:np.array, hidden_units:int):\n",
        "    \"\"\"\n",
        "    Input and output matrices are of same dimension\n",
        "    Single dense layer with a specified number of hidden units\n",
        "\n",
        "\n",
        "    :param X: input matrix\n",
        "    :type X: np.array\n",
        "    :param hidden_units: number of hidden units\n",
        "    :type hidden_units: int\n",
        "    \"\"\"\n",
        "    input_dim = X.shape[1]\n",
        "    \n",
        "    # golorot normal initialization of the weights\n",
        "    weight = init_weights(input_dim, hidden_units )\n",
        "\n",
        "    bias = np.zeros(hidden_units)\n",
        "    \n",
        "    # we use the dot product to calculate the output of the layer\n",
        "    return np.matmul(X, weight) + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 512)"
            ]
          },
          "execution_count": 366,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense_output = dense_layer(positional_encoding_matrix, 512)\n",
        "dense_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsSfCiNKs9xj"
      },
      "source": [
        "## Task 1.3\n",
        "Implement all activation function such that they are compatible with the dense layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "id": "tg6qEQPws9xk"
      },
      "outputs": [],
      "source": [
        "# Implement all activation function such that they are compatible with the dense layer.\n",
        "def activation(hidden_layer:np.array):\n",
        "    \"\"\" Relu activation\n",
        "\n",
        "    :param hidden_layer: hidden layer for activation\n",
        "    :type hidden_layer: np.array\n",
        "    :param activation: ReLU activated hidden layer\n",
        "    :type activation: np.array\n",
        "    \"\"\"\n",
        "    # Implement the relu activation function\n",
        "    return np.maximum(0, hidden_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.09472957, ..., 0.39112737, 0.39293197,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.2611717 , ..., 0.65277553, 0.12052044,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.4738368 , ..., 0.82693652, 0.02108683,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.64920994, ..., 0.84064954, 0.1577539 ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.73261486, ..., 0.72028758, 0.45373362,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.72271556, ..., 0.56048757, 0.73353649,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 368,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "activation(dense_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lyam5O3s9xl"
      },
      "source": [
        "## Task 1.4\n",
        "Implement the skip (residual) connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 369,
      "metadata": {
        "id": "JeaLA_N5s9xn"
      },
      "outputs": [],
      "source": [
        "#Implement the skip (residual) connections.\n",
        "def skip_connections(hidden_layer, input_layer):\n",
        "    \"\"\"Skip connection \n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    :param input_layer: _description_\n",
        "    :type input_layer: _type_\n",
        "    \"\"\"\n",
        "    return hidden_layer + input_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8cryIa1s9xn"
      },
      "source": [
        "## Task 1.5\n",
        "Implement layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "id": "gyYe-KH3s9xo"
      },
      "outputs": [],
      "source": [
        "# Implement layer normalization.\n",
        "def normalisation_layer(hidden_layer):\n",
        "    \"\"\" check the dimensionality should be normalised over all values \n",
        "    instead of columns wise normalisation used in batch normalisation\n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    :param mean: _description_\n",
        "    :type mean: _type_\n",
        "    :param variance: _description_\n",
        "    :type variance: _type_\n",
        "    \"\"\"\n",
        "    # Implement the layer normalization\n",
        "    mean = np.mean(hidden_layer, axis=1, keepdims=True)\n",
        "    variance = np.var(hidden_layer, axis=1, keepdims=True)\n",
        "    return (hidden_layer - mean) / np.sqrt(variance + 1e-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKIJqC2us9xp"
      },
      "source": [
        "## Task 1.6\n",
        "Implement dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {
        "id": "RUhGgH_qs9xq"
      },
      "outputs": [],
      "source": [
        "# Implement dropout\n",
        "def drop_out(hidden_layer, dropout_rate):\n",
        "    \"\"\"dropout \n",
        "\n",
        "    :param hidden_layer: _description_\n",
        "    :type hidden_layer: _type_\n",
        "    :param dropout_rate: _description_\n",
        "    :type dropout_rate: _type_\n",
        "    \"\"\"\n",
        "    # Implement the dropout\n",
        "    return hidden_layer * np.random.binomial(1, 1 - dropout_rate, size=hidden_layer.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtCKnQJys9xy"
      },
      "source": [
        "## Task 1.7\n",
        "Implement the attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {},
      "outputs": [],
      "source": [
        "def softmax(input_matrix):\n",
        "    \"\"\"Softmax activation\n",
        "\n",
        "    :param input_matrix: Input matrix\n",
        "    :type input_matrix: np.array\n",
        "    \"\"\"\n",
        "    # Implement the softmax function\n",
        "    return np.exp(input_matrix) / np.sum(np.exp(input_matrix), axis=1, keepdims=True)\n",
        " \n",
        "def attention(query, key, value, mask=None, dropout_rate=None):\n",
        "    \"\"\"Compute 'Scaled Dot Product Attention'\n",
        "\n",
        "    :param query: query matrix resulting from the dot product of the x and the query weights of shape (seq_len, d_model).\n",
        "    :type query: np.array\n",
        "    :param key: key matrix resulting from the dot product of the x and the key weights of shape (seq_len, d_model).\n",
        "    :type key: np.array\n",
        "    :param value: value matrix resulting from the dot product of the x and the value weights of shape (seq_len, d_model).\n",
        "    :type value: np.array\n",
        "    :param mask: boolean mask, defaults to None\n",
        "    :type mask: boolen, optional\n",
        "    :param dropout: boolean dropout, defaults to None\n",
        "    :type dropout: boolen, optional\n",
        "    :return: output of shape (seq_len, d_model).\n",
        "    :rtype: np.array\n",
        "    \"\"\"    \"\"\"\"\"\"\n",
        "    # Implement the attention mechanism\n",
        "    dimension_k = key.shape[1]\n",
        "    scores = np.matmul(query, key.T) / np.sqrt(dimension_k)\n",
        "    if mask is not None:\n",
        "        scores = mask_attention_scores(scores, mask_value=-np.inf)\n",
        "    predicted_attention = softmax(scores)\n",
        "    if dropout_rate is not None:\n",
        "        predicted_attention = drop_out(predicted_attention, dropout_rate=dropout_rate)\n",
        "    return np.matmul(predicted_attention, value)\n",
        "\n",
        "# Implement the mask function\n",
        "\n",
        "def mask_attention_scores(scores, mask_value=-np.inf):\n",
        "    \"\"\"\n",
        "    Apply a mask to attention scores.\n",
        "\n",
        "    :param scores: Attention scores of shape (num_heads, seq_len, seq_len).\n",
        "\n",
        "    :returns: Masked attention scores of shape (num_heads, seq_len, seq_len).\n",
        "    \"\"\"\n",
        "    # Create mask of shape (seq_len, seq_len)\n",
        "    attn_shape = scores.shape\n",
        "    mask = np.tril(np.ones(attn_shape), k=0)\n",
        "\n",
        "    # Set masked positions to mask_value\n",
        "    masked_scores = np.where(mask == 0, mask_value, scores)\n",
        "    # print('masked_scores', masked_scores.shape)\n",
        "    return masked_scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# implement a multi-head attention layer\n",
        "def multihead_attention(query, key, value, query_projections, key_projections, value_projections, o_projections, mask:bool = None, dropout_rate:float = None, num_heads:int = 8):\n",
        "    \"\"\"\n",
        "    Compute multihead self-attention given query, key, and value matrices.\n",
        "\n",
        "    :param query: query matrix resulting from the dot product of the x and the query weights of shape (seq_len, d_model).\n",
        "    :type query: np.array\n",
        "    :param key: key matrix resulting from the dot product of the x and the key weights of shape (seq_len, d_model).\n",
        "    :type key: np.array\n",
        "    :param value: value matrix resulting from the dot product of the x and the value weights of shape (seq_len, d_model).\n",
        "    :type value: np.array\n",
        "    :param query_projections: Query projectionss of shape (d_model, d_model).\n",
        "    :type query_projections: np.array\n",
        "    :param key_projections: Key projectionss of shape (d_model, d_model).\n",
        "    :type key_projections: np.array\n",
        "    :param value_projections: Value projectionss of shape (d_model, d_model).\n",
        "    :type value_projections: np.array\n",
        "    :param o_projections: Output projectionss of shape (d_model, d_model).\n",
        "    :type o_projections: np.array\n",
        "    :param mask: Mask for attention, defaults to None\n",
        "    :type mask: bool, optional\n",
        "    :param dropout_rate: Dropout rate, defaults to None\n",
        "    :type dropout_rate: float, optional\n",
        "    :param num_heads: Number of heads for attention.\n",
        "    :type num_heads: int, optional\n",
        "\n",
        "    :returns: Output of multihead attention of shape (seq_len, d_model).\n",
        "    \"\"\"\n",
        "    \n",
        "    # Project query, key, and value matrices using learnable projectionss\n",
        "    query_projected = np.matmul(query, query_projections)\n",
        "    key_projected = np.matmul(key, key_projections)\n",
        "    value_projected = np.matmul(value, value_projections)\n",
        "    \n",
        "\n",
        "    # Split matrices into multiple heads\n",
        "    query_heads = np.array(np.split(query_projected, num_heads, axis=1))\n",
        "    key_heads = np.array(np.split(key_projected, num_heads, axis=1))\n",
        "    value_heads = np.array(np.split(value_projected, num_heads, axis=1))\n",
        "        \n",
        "    # print(query_heads.shape)\n",
        "    \n",
        "\n",
        "    # Compute scaled dot product attention for each head\n",
        "    head_outputs = []\n",
        "    for i in range(num_heads):\n",
        "        query_i = query_heads[i]\n",
        "        key_i = key_heads[i]\n",
        "        value_i = value_heads[i]\n",
        "\n",
        "        # Compute attention scores\n",
        "        attention_scores = attention(query_i, key_i, value_i, mask, dropout_rate)\n",
        "\n",
        "        # Append attention scores to head_outputs\n",
        "        head_outputs.append(attention_scores)\n",
        "\n",
        "    # Concatenate head outputs and project back to original dimensionality\n",
        "    outputs = np.concatenate(head_outputs, axis=-1)\n",
        "    \n",
        "    # reproject the output\n",
        "    outputs_projected = np.matmul(outputs, o_projections)\n",
        "\n",
        "    return outputs_projected\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 512)"
            ]
          },
          "execution_count": 373,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positional_encoding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {},
      "outputs": [],
      "source": [
        "# query_weights, key_weights, value_weights, o_weights = init_weights(512, 512), init_weights(512, 512), init_weights(512, 512), init_weights(512, 512)\n",
        "# query, key, value = np.matmul(positional_encoding_matrix, query_weights), np.matmul(positional_encoding_matrix, key_weights), np.matmul(positional_encoding_matrix, value_weights)\n",
        "\n",
        "# attention_output = multihead_attention(query, key, value, query_weights, key_weights, value_weights, o_weights, mask = False, dropout_rate = 0.1, num_heads = 8)\n",
        "# print(attention_output.shape)\n",
        "# attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# drop one row of the query matrix and check the output\n",
        "# query_weights, key_weights, value_weights, o_weights = init_weights(512, 512), init_weights(512, 512), init_weights(512, 512), init_weights(512, 512)\n",
        "# query, key, value = np.matmul(positional_encoding_matrix, init_weights(512, 512)), np.matmul(positional_encoding_matrix, init_weights(512, 512)), np.matmul(positional_encoding_matrix, init_weights(512, 512))\n",
        "# attention_masked = multihead_attention(query, key, value, query_weights, key_weights, value_weights, o_weights, mask = True, dropout_rate = 0.1, num_heads = 8)\n",
        "# print(attention_masked.shape)\n",
        "# attention_masked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yApJ-i6Ws9x0"
      },
      "source": [
        "## Task 1.8\n",
        "Implement the positonal feed-forward network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "PgOD1435s9x1"
      },
      "outputs": [],
      "source": [
        "# included in Task 1.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhyAVEIas9x1"
      },
      "source": [
        "## Task 1.9\n",
        "Implement the encoder attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "KhVWrtbls9x1"
      },
      "outputs": [],
      "source": [
        "# included in Task 1.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4lA-qajs9x2"
      },
      "source": [
        "## Task 1.10\n",
        "Implement the encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "id": "XnDRK_aPs9x2"
      },
      "outputs": [],
      "source": [
        "# included in Task 1.14\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzqspeJ4s9x2"
      },
      "source": [
        "## Task 1.11\n",
        "Implement the decoder attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {
        "id": "YEgfyNvNs9x3"
      },
      "outputs": [],
      "source": [
        "# included in Task 1.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lOPMNIps9x3"
      },
      "source": [
        "## Task 1.12\n",
        "Implement the encoder-decoder attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {
        "id": "lLQ8aRPTs9x3"
      },
      "outputs": [],
      "source": [
        "# included in Task 1.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZW9JEaUs9x4"
      },
      "source": [
        "## Task 1.13\n",
        "Implement the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "id": "3bQZWQrns9x4"
      },
      "outputs": [],
      "source": [
        "# included in Task 1.14\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtPOUkLRs9x4"
      },
      "source": [
        "## Task 1.14\n",
        "Implement the transformer architecture (e.g. by creating a Transformer class that includes the steps before)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "id": "VEtaTIR_s9x5"
      },
      "outputs": [],
      "source": [
        "class Transformer():\n",
        "    def __init__(self, vocab_size, d_model, attention_layers, d_hidden, padding=512, dropout=0.1):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.attention_layers = attention_layers\n",
        "        self.d_hidden = d_hidden\n",
        "        self.padding = padding\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # initialise weights for embedding\n",
        "        self.W_embedding_encoder = init_weights(vocab_size, d_model)  # embedding matrix for encoder\n",
        "        self.W_embedding_decoder = init_weights(vocab_size, d_model)  # embedding matrix for decoder\n",
        "        \n",
        "        \n",
        "        list_weights = [init_weights(d_model, d_model) for i in range(attention_layers)] # template for weights for dimensionality (d_model, d_model）  \n",
        "        \n",
        "        # initialise weights for encoder attention\n",
        "        self.W_K_encoder, self.W_Q_encoder, self.W_V_encoder = list_weights, list_weights, list_weights # list of weights for K, Q, V for all attention layers\n",
        "        self.query_projections_enc, self.key_projections_enc, self.value_projections_enc, self.o_projections_enc = list_weights,list_weights,list_weights,list_weights # list of Projection weights for K, Q, V for all attention layers\n",
        "        \n",
        "        # initialise weights for decoder attention\n",
        "        self.W_K_decoder, self.W_Q_decoder, self.W_V_decoder = list_weights, list_weights, list_weights # list of weights for K, Q, V for all attention layers\n",
        "        self.query_projections_dec, self.key_projections_dec, self.value_projections_dec, self.o_projections_dec = list_weights,list_weights,list_weights,list_weights # list of Projection weights for K, Q, V for all attention layers\n",
        "\n",
        "        # initialise weights for encoder-decoder attention\n",
        "        self.W_Q_encoder_decoder, self.W_K_encoder_decoder, self.W_V_encoder_decoder = list_weights, list_weights, list_weights # list of weights for K, Q, V for all attention layers\n",
        "        self.query_projections_enc_dec, self.key_projections_enc_dec, self.value_projections_enc_dec, self.o_projections_enc_dec = list_weights,list_weights,list_weights,list_weights # list of Projection weights for K, Q, V for all attention layers\n",
        "\n",
        "        # parameter for encoder feed forward \n",
        "        self.W_1_enc = [init_weights(d_model, d_hidden) for i in range(attention_layers)]\n",
        "        self.b_1_enc = [init_weights(1, d_hidden) for i in range(attention_layers)]\n",
        "        self.W_2_enc = [init_weights(d_hidden, d_model) for i in range(attention_layers)]\n",
        "        self.b_2_enc = [init_weights(1, d_model) for i in range(attention_layers)]\n",
        "        \n",
        "        # parameter for decoder feed forward \n",
        "        self.W_1_dec = [init_weights(d_model, d_hidden) for i in range(attention_layers)]\n",
        "        self.b_1_dec = [init_weights(1, d_hidden) for i in range(attention_layers)]\n",
        "        self.W_2_dec = [init_weights(d_hidden, d_model) for i in range(attention_layers)]\n",
        "        self.b_2_dec = [init_weights(1, d_model) for i in range(attention_layers)]\n",
        "\n",
        "        # parameter for linear layer\n",
        "        #self.W, self.b = init_weights(len(forward_pass_array_output) * d_model, self.vocab_size), init_weights(1, self.vocab_size)\n",
        "        self.W, self.b = init_weights(self.padding * d_model, self.vocab_size), init_weights(1, self.vocab_size)\n",
        "\n",
        "        # parameter for layer normlisation\n",
        "        self.a_ln_1_enc = np.ones(attention_layers) # first layer norm for encoder\n",
        "        self.b_ln_1_enc = np.zeros(attention_layers) # first layer norm for encoder\n",
        "\n",
        "        self.a_ln_2_enc = np.ones(attention_layers) # second layer norm for encoder\n",
        "        self.b_ln_2_enc = np.zeros(attention_layers) # second layer norm for encoder\n",
        "\n",
        "        self.a_ln_1_dec = np.ones(attention_layers) # first layer norm for decoder\n",
        "        self.b_ln_1_dec = np.zeros(attention_layers) # first layer norm for decoder\n",
        "\n",
        "        self.a_ln_2_dec = np.ones(attention_layers) # second layer norm for decoder\n",
        "        self.b_ln_2_dec = np.zeros(attention_layers) # second layer norm for decoder\n",
        "\n",
        "        self.a_ln_3_dec = np.ones(attention_layers) # second layer norm for decoder\n",
        "        self.b_ln_3_dec = np.zeros(attention_layers) # second layer norm for decoder\n",
        "\n",
        "    def forward(self, input_enc, input_dec, mask=None):\n",
        "        output_enc = self.encoder(input_enc, n_layers=self.attention_layers)  \n",
        "        out_prob = self.decoder(input_dec, output_enc, n_layers=self.attention_layers, mask=mask) # \n",
        "        return out_prob # output of encoder\n",
        "\n",
        "    def encoder(self, x, n_layers=6):\n",
        "        x = np.pad(x, (0, self.padding-len(x)), 'constant') # pad the input to the maximum length of the input\n",
        "        x = self.W_embedding_encoder[x] # get the embedding of the padded input\n",
        "        x += positional_encoding(x)  # add the positional encoding to the embedding\n",
        "        x = drop_out(x, self.dropout)  # apply dropout to the sums of the embeddings and the positional encodings\n",
        "    \n",
        "        for i in range(n_layers):\n",
        "            # get query, key, value\n",
        "            query_encoder = np.matmul(x, self.W_Q_encoder[i]) # get the query\n",
        "            key_encoder = np.matmul(x, self.W_K_encoder[i]) # get the key\n",
        "            value_encoder = np.matmul(x, self.W_V_encoder[i]) # get the value\n",
        "            self_attenion = multihead_attention(query_encoder, key_encoder, value_encoder, self.query_projections_enc[i], self.key_projections_enc[i], self.value_projections_enc[i], self.o_projections_enc[i], mask=None, dropout_rate = self.dropout, num_heads = 8) # get the self attention\n",
        "\n",
        "            x += skip_connections(x, self_attenion)  # apply dropout to the output of each sub-layer, before it is added to the sub-layer input and normalized.\n",
        "            x = self.layer_norm(x, self.a_ln_1_enc[i], self.b_ln_1_enc[i]) # apply layer normalisation\n",
        "\n",
        "            # feed forward\n",
        "            x += skip_connections(x, drop_out(self.feed_forward(x, self.W_1_enc[i], self.b_1_enc[i], self.W_2_enc[i], self.b_2_enc[i]),dropout_rate=self.dropout))\n",
        "            x = self.layer_norm(x, self.a_ln_2_enc[i], self.b_ln_2_enc[i]) # apply layer normalisation\n",
        "        return x\n",
        "\n",
        "\n",
        "    def decoder(self, x, y, n_layers=6, mask=None):\n",
        "        \"\"\"\n",
        "        x: input of decoder, \n",
        "        y: output of encoder, \n",
        "        n_layers: number of layers in decoder,\n",
        "        mask: mask for decoder attention\n",
        "        \"\"\"\n",
        "        x = np.pad(x, (0, self.padding-len(x)), 'constant') # pad input to the same length\n",
        "        x = self.W_embedding_decoder[x]\n",
        "        x += positional_encoding(x)\n",
        "        x = drop_out(x, 0.1)  # apply dropout to the sums of the embeddings and the positional encodings\n",
        "    \n",
        "        for i in range(n_layers):\n",
        "            # get query, key, value for decoder attention\n",
        "            query_decoder = np.matmul(x, self.W_Q_decoder[i]) # get the query\n",
        "            key_decoder = np.matmul(x, self.W_K_decoder[i])  # get the key\n",
        "            value_decoder = np.matmul(x, self.W_V_decoder[i])  # get the value\n",
        "            # decoder attention\n",
        "            self_attenion = multihead_attention(query_decoder, key_decoder, value_decoder, self.query_projections_dec[i], self.key_projections_dec[i], self.value_projections_dec[i], self.o_projections_dec[i], mask=mask, dropout_rate = self.dropout, num_heads = 8)\n",
        "            x += skip_connections(x, self_attenion)  # apply dropout to the output of each sub-layer, before it is added to the sub-layer input and normalized.\n",
        "            x = self.layer_norm(x, self.a_ln_1_dec[i], self.b_ln_1_dec[i]) # apply layer normalisation\n",
        "    \n",
        "            # get query, key, value for encoder-decoder attention\n",
        "            query_encoder_decoder = np.matmul(x, self.W_Q_encoder_decoder[i])  # from decoder attention\n",
        "            key_encoder_decoder = np.matmul(y, self.W_K_encoder_decoder[i]) # from encoder attention\n",
        "            value_encoder_decoder = np.matmul(y, self.W_V_encoder_decoder[i])  # from encoder attention\n",
        "            # encoder-decoder attention\n",
        "            attenion = multihead_attention(query_encoder_decoder, key_encoder_decoder, value_encoder_decoder, self.query_projections_enc_dec[i], self.key_projections_enc_dec[i], self.value_projections_enc_dec[i], self.o_projections_enc_dec[i], mask=None, dropout_rate = self.dropout, num_heads = 8)\n",
        "            x += skip_connections(x, attenion)  # apply dropout to the output of each sub-layer, before it is added to the sub-layer input and normalized.\n",
        "            x = self.layer_norm(x, self.a_ln_2_dec[i], self.b_ln_2_dec[i])\n",
        "    \n",
        "            # feed forward\n",
        "            x += skip_connections(x, drop_out(self.feed_forward(x, self.W_1_dec[i], self.b_1_dec[i], self.W_2_dec[i], self.b_2_dec[i]), dropout_rate=self.dropout))\n",
        "            x = self.layer_norm(x, self.a_ln_3_dec[i], self.b_ln_3_dec[i]) # apply layer normalisation\n",
        "    \n",
        "        # flatten 2D matrix to 1D vector\n",
        "        x = x.flatten().squeeze()\n",
        "        # linear layer\n",
        "        x = self.linear_layer(x)\n",
        "        output = softmax(x)\n",
        "    \n",
        "        return output\n",
        "\n",
        "    def layer_norm(self, hidden_layer, a, b):\n",
        "\n",
        "        # Implement the layer normalization\n",
        "        mean = np.mean(hidden_layer, axis=1, keepdims=True)\n",
        "        variance = np.var(hidden_layer, axis=1, keepdims=True)\n",
        "        #print(a.shape,hidden_layer.shape)\n",
        "        return a * (hidden_layer - mean) / np.sqrt(variance + 1e-8) + b\n",
        "    \n",
        "    def linear_layer(self, x):\n",
        "        x = np.matmul(x, self.W) + self.b\n",
        "        x = drop_out(x, self.dropout)\n",
        "        return x\n",
        "    \n",
        "    def feed_forward(self, x, W_1, b_1, W_2, b_2):\n",
        "        x = np.matmul(x, W_1) + b_1\n",
        "        x = activation(x)\n",
        "        x = np.matmul(x, W_2) + b_2\n",
        "        x = drop_out(x, self.dropout)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARMrtlX-s9x5"
      },
      "source": [
        "## Task 1.15\n",
        "Test the forward pass using the follow array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "id": "XVwUBmyqs9x6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.02904019336836183\n",
            "256\n"
          ]
        }
      ],
      "source": [
        "forward_pass_array_input = np.array([1, 40, 50, 60, 17, 12]) # input for encoder\n",
        "forward_pass_array_output = np.array([12, 48, 50, 63]) # temporary input for decoder\n",
        "\n",
        "transformer = Transformer(vocab_size=1000, d_model=512, attention_layers=6, d_hidden=2048, padding=512, dropout=0.1)\n",
        "output = transformer.forward(forward_pass_array_input, forward_pass_array_output, mask=True)\n",
        "\n",
        "print(output.max())\n",
        "print(output.argmax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVQhmTVs9x6"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a8mqbvis9x7"
      },
      "source": [
        "In the following, we want to use pretrained models. From here on, you are allowed to use any machine learning frame work of your choice. Moreover, you will use [Hugging Face](https://huggingface.co/) which is compatible with tensorflow, keras, torch and other machine learning frameworks.\n",
        "\n",
        "We want to fine-tune a pretrained model to determine whether Yelp reviews are positive or negative. The data set is available for [Tensorflow](https://www.tensorflow.org/datasets/catalog/yelp_polarity_reviews) and [(py)torch](https://pytorch.org/text/stable/datasets.html#yelpreviewpolarity). Given the text of a review, we want to determine whether the yelp review is positive and negative. The data set is pre-split into training and test set. Please use the training data to fine-tune your model, while using the test data to evaluate your models performance. This exercise does not necessarily end in having a SOTA model, the goal is for you to use and fine-tune SOTA pretrained large language models.\n",
        "\n",
        "Problem Setting:\n",
        "\n",
        "The label $y$ to a Yelp review $T$ is either positive or negative. Given a Yelp Review $T$ and a polarity feedback $y$ determine whether the Review $T$ is positive or negative. The training set $\\mathcal{D} = \\{(T_1, y_1), \\ldots, (T_N, y_N)\\}$, where $T_i$ is review $i$ and $y_i$ is $T_i$'s polarity feedback. A suitable evaluation metric for this type of problem is $\\rightarrow$ see Theory Question 1.\n",
        "\n",
        "In the following, please solve all subtasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeeKpVG6s9x7"
      },
      "source": [
        "## Theory Question 1\n",
        "Which metric is threshold independent to evaluate the problem setting described in Task 2. Please list pros and cons of three different metrics that might be suitable, define an evaluation protocol and decide which evaluation suits this problem best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXMOXCwCs9x8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDmbdj-Ds9x8"
      },
      "source": [
        "## Task 2.0\n",
        "Load the Yelp Review Polarity dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3-cPKGuus9x9"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import YelpReviewPolarity\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Load YelpReviewPolarity dataset, split into train and test\n",
        "# datatype: ShardingFilterIterDataPipe\n",
        "train_data, test_data = YelpReviewPolarity(root='.data', split=('train', 'test'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlRochOKs9x9"
      },
      "source": [
        "## Task 2.1\n",
        "Decide on a suitable language model from the HuggingFace model zoo (a library providing pretrained models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nap1PL1es9x9"
      },
      "outputs": [],
      "source": [
        "# included in Task 2.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h0rgHM9s9x-"
      },
      "source": [
        "## Task 2.2\n",
        "\n",
        "For the model to process the intended way, we need the tokenizer that was used during training. Luckily Hugging Face  provides both pretrained models and tokenizer. After in Task 2.1 decided for a language model, please load the corresponding tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klRNm499s9x-"
      },
      "outputs": [],
      "source": [
        "# included in Task 2.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZwxqrDs9x_"
      },
      "source": [
        "## Task 2.3\n",
        "Load the language model from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dfk7kebFs9x_"
      },
      "outputs": [],
      "source": [
        "# included in Task 2.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRcPP6sPs9x_"
      },
      "source": [
        "## Task 2.4\n",
        "Fine-tune your model on the Yelp Review Polarity training data set. Note: If you have computational limitations consider fine-tuning only on part of the training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13Nx72o_s9yA"
      },
      "outputs": [],
      "source": [
        "# Define a collate function that applies the tokenizer to each batch\n",
        "def collate_fn(batch):\n",
        "    # Convert the list of inputs and labels to separate lists\n",
        "    labels, inputs = zip(*batch)\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    # Tokenize the inputs\n",
        "    tokenized_inputs = tokenizer(inputs, padding=True, add_special_tokens=True,  truncation=True, return_tensors=\"pt\")\n",
        "    tokenizer(inputs, padding='max_length', max_length=512, add_special_tokens=True, truncation=True, return_tensors=\"pt\")\n",
        "    # Convert the labels to a PyTorch tensor\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    # Return the tokenized inputs and labels as a tuple\n",
        "    return tokenized_inputs, labels\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"BERT model for classification.This module is composed of the BERT model with a linear layer on top of the pretrained BERT model.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased', output_attentions=True)\n",
        "        # Freeze the BERT parameters if desired\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output, _ = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        prob = self.softmax(linear_output)\n",
        "\n",
        "        return prob\n",
        "\n",
        "class TimingCallback(torch.nn.Module):\n",
        "    def __init__(self,total_epochs ):\n",
        "        super(TimingCallback, self).__init__()\n",
        "        self.total_epochs = total_epochs\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def forward(self, epoch, total_epochs):\n",
        "        elapsed_time = time.time() - self.start_time\n",
        "        print(\"Epoch [{}/{}] - time: {:.2f}s\".format(epoch + 1, total_epochs, elapsed_time))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.forward(epoch, self.total_epochs)\n",
        "\n",
        "def train(model, train_data):\n",
        "    train_loader = DataLoader(train_data, batch_size=batchSize, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "        model.train()\n",
        "        for i, data in tqdm(enumerate(train_loader)):\n",
        "            if i == sample:\n",
        "                break\n",
        "            train_input, train_label = data\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_input['attention_mask'].to(device)\n",
        "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask) #\n",
        "\n",
        "            batch_loss = criterion(output, (train_label-1).long())\n",
        "            total_loss_train += batch_loss.item()\n",
        "\n",
        "            acc = (output.argmax(dim=1) == train_label-1).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            model.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        timing_callback.on_epoch_end(epoch, epochs)\n",
        "        print(f'Train Loss: {total_loss_train / (i*batchSize): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / (i*batchSize): .3f}' )\n",
        "\n",
        "# initialize the parameters\n",
        "batchSize = 16\n",
        "epochs = 10\n",
        "lr = 1e-6\n",
        "sample = 1000 # number of batches\n",
        "model = BertClassifier(freeze_bert=False) # initialize the model\n",
        "\n",
        "# Load YelpReviewPolarity dataset, split into train and test\n",
        "# datatype: ShardingFilterIterDataPipe\n",
        "train_data, test_data = YelpReviewPolarity(root='.data', split=('train', 'test'))\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Train the model and evaluate its performance\n",
        "timing_callback = TimingCallback(epochs)\n",
        "train(model, train_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaGqCcEs9yB"
      },
      "source": [
        "## Task 2.5\n",
        "Evaluate your model, following the evaluation protocol you defined in Theory Question 1, on the test part of the Yelp Review Polarity data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdqnnJaGs9yC"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_data):\n",
        "    test_loader = DataLoader(test_data, batch_size=batchSize, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model = model.to(device)\n",
        "    total_loss_test = 0\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, data in tqdm(enumerate(test_loader)):\n",
        "            if i == sample:\n",
        "                break\n",
        "            test_input, test_label = data\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_input['attention_mask'].to(device)\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "            batch_loss = criterion(output, (test_label-1).long())\n",
        "            total_loss_test += batch_loss.item()\n",
        "\n",
        "            acc = (output.argmax(dim=1) == test_label-1).sum().item()\n",
        "            total_acc_test += acc\n",
        "\n",
        "    print(f'Test Loss: {total_loss_test / (i * batchSize): .3f} \\\n",
        "            | Test Accuracy: {total_acc_test / (i * batchSize): .3f}')\n",
        "\n",
        "#model = BertModel.from_pretrained('bert-base-uncased', output_attentions=True)\n",
        "#model.load_state_dict(torch.load(\"model.pth\", map_location=device))  \n",
        "evaluate(model, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEibR93Hs9yC"
      },
      "source": [
        "# Task 3\n",
        "Visualize and interpret the attention weights of one correctly and one of the incorrectly classified examples of the Yelp Review Polarity test data using [BertViz](https://github.com/jessevig/bertviz)'s model_view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1YPLr3cs9yC"
      },
      "outputs": [],
      "source": [
        "from bertviz import model_view\n",
        "\n",
        "correct_example = None\n",
        "incorrect_example = None\n",
        "\n",
        "# get one correctly and one incorrectly classified example\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "model = model.to(device)\n",
        "for i, data in tqdm(enumerate(test_loader)):\n",
        "    test_input, test_label = data\n",
        "    test_label = test_label.to(device)\n",
        "    mask = test_input['attention_mask'].to(device)\n",
        "    input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "    output = model(input_id, mask)\n",
        "    \n",
        "    if output[0][0] > 0.5:\n",
        "        pred = 2\n",
        "    else:\n",
        "        pred = 1\n",
        "\n",
        "    if pred == test_label and correct_example is None:\n",
        "        correct_example = test_input\n",
        "    elif pred != test_label and incorrect_example is None:\n",
        "        incorrect_example = test_input\n",
        "    \n",
        "    if correct_example is not None and incorrect_example is not None:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask = correct_example['attention_mask'].to(device)\n",
        "input_id = correct_example['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "# visualize correctly classified example\n",
        "outputs = model(input_id, mask)  # Run model\n",
        "attention = outputs[-1]  # Retrieve attention from model outputs\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_id[0])  # Convert input ids to token strings\n",
        "model_view(attention, tokens)  # Display model view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask = incorrect_example['attention_mask'].to(device)\n",
        "input_id = incorrect_example['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "# visualize incorrectly classified example\n",
        "outputs = model(input_id, mask)  # Run model\n",
        "attention = outputs[-1]  # Retrieve attention from model outputs\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_id[0])  # Convert input ids to token strings\n",
        "model_view(attention, tokens)  # Display model view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm05PFcMs9yD"
      },
      "source": [
        "## Theory Question 2\n",
        "In your own words, describe how the attention mechanism in a transformer works in the case of self-attention and cross-attention, identifying in each case the keys, queries, and values. Give two examples of alignment models and describe how they affect the output using a simple example. This part of the written report can be done in collaboration with your group."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Self-attention:</h4>\n",
        "The keys, queries, and values are derived from the same input sequence. The attention function computes a weighted sum of the values based on the similarity between the queries and keys. The similarity scores are computed by taking the dot product between the queries and keys and applying a softmax function to normalize the scores. The resulting weighted sum is used as the output for that position in the sequence.\n",
        "\n",
        "- Query: Token at current processing stage\n",
        "- Keys: All tokens from the same sequence to which we pay attention\n",
        "- Values: Transformed keys that are used for the weighted sum\n",
        "\n",
        "\n",
        "<h4>Cross-attention:</h4> \n",
        "The keys, queries, and values come from different input sequences. For example, when translating a sentence from one language to another, the queries come from the sequence in the target language while the keys and values come from the sequence in the source language.\n",
        "\n",
        "- Query: Token at current processing stage (in Decoder layer)\n",
        "- Keys: All tokens from the output of the Encoder to which we pay attention\n",
        "- Values: Transformed keys that are used for the weighted sum\n",
        "\n",
        "\n",
        "<h4>Alignment models:</h4> \n",
        "Example: Translate \"The man\" from English to French (\"l'homme\")\n",
        "\n",
        "- <b> Bahdanau/additive attention:</b>  In this case, h<sub>j</sub> is a concatenation of the forward- and backward states of a single bi-directional RNN. The vectors s<sub>t-1</sub> (preceding Decoder-state) and h<sub>j</sub> (Encoder hidden state) are then passed throught a single-layer feed-forward neural network. Considering our example, this attention mechanism would learn that while generating \"l'\", \"man\" has a high importance to generate the correct French article.\n",
        "- <b>Dot product:</b> The alignment score solely depends on the similarity (represented by the dot product between two vectors) of the vectors s<sub>t-1</sub> and h<sub>j</sub>. The importance of \"man\" while generating \"l'\" therefore depends on the similarity of the encoded hidden state of \"man\" and the preceding decoder state while generating \"l'\". Instead of the attention neural network (like above) learning that this should result in a high alignment score, the Encoder/Decoder must learn to generate s<sub>t-1</sub> and h<sub>j</sub> in a way that they result in a large dot product for \"man\" and \"l'\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u-8cqs0s9yD"
      },
      "source": [
        "# Task 4\n",
        "Please describe your team's implementation of this project, including your personal contribution, in 1000-1500 characters. Each team member must explain the main aspects of the team's implementation, and may not discuss this summary with other students. You are allowed to use figures and tables to clarify. This summary constitutes a separately and individually graded piece of work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7FJBhNPs9yE"
      },
      "outputs": [],
      "source": [
        "jhk"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
